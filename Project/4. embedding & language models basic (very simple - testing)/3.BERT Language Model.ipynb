{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOZ25pHdBdo5SAXegaiIW83"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nByllnm0nvPD","executionInfo":{"status":"ok","timestamp":1734205775775,"user_tz":-210,"elapsed":3397,"user":{"displayName":"Mohammad z","userId":"08211557771918752526"}},"outputId":"06547869-65e2-496c-de52-d02ce539fb87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","from transformers import pipeline\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/IUT/IR/project/4. embedding & language models/train.csv')\n","\n","sampled_data = data.sample(n=1000, random_state=42)\n","sentences = sampled_data['Title'].tolist()"],"metadata":{"collapsed":true,"id":"VgzsH1mPn2DQ","executionInfo":{"status":"ok","timestamp":1734205777616,"user_tz":-210,"elapsed":776,"user":{"displayName":"Mohammad z","userId":"08211557771918752526"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForMaskedLM\n","import torch\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","\n","def generate_sentence(sentence, mask=\"[MASK]\"):\n","    tokens = tokenizer.tokenize(sentence)\n","\n","    masked_index = len(tokens) // 2\n","    tokens[masked_index] = mask\n","\n","    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","    input_ids_tensor = torch.tensor([input_ids])\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids_tensor)\n","        predictions = outputs.logits\n","\n","    predicted_index = torch.argmax(predictions[0, masked_index]).item()\n","    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n","\n","    tokens[masked_index] = predicted_token\n","\n","    return tokenizer.convert_tokens_to_string(tokens)\n","\n","augmented_sentences = []\n","for sentence in sentences:\n","    new_sentence = generate_sentence(sentence)\n","    augmented_sentences.append(new_sentence)\n","    augmented_sentences.append(new_sentence)\n","\n","\n","augmented_data = pd.DataFrame({\n","    'Original': sentences * 2,\n","    'Generated': augmented_sentences\n","})\n","\n","augmented_data.to_csv('/content/drive/MyDrive/IUT/IR/project/4. embedding & language models/augmented_dataset.csv', index=False)\n","\n","print(\"Dataset has been saved as 'augmented_dataset.csv'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"GMpXrMyhozpy","executionInfo":{"status":"ok","timestamp":1734205782057,"user_tz":-210,"elapsed":1237,"user":{"displayName":"Mohammad z","userId":"08211557771918752526"}},"outputId":"743a9fd5-92ef-4a3b-c995-acf6f1264300"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Dataset has been saved as 'augmented_dataset.csv'\n"]}]}]}